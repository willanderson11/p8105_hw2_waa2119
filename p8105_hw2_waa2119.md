p8105_hw2_waa2119
================
William Anderson
2022-09-30

``` r
library(tidyverse)
library(dplyr)
library(readxl)
```

# Homework 2

## Problem 1

First we will read in the data about entrance and exits for subway
stations in NYC

We will retain line, station, name, station latitude / longitude, routes
served, entry, vending, entrance type, and ADA compliance then convert
the entry variable from character to a logical variable

``` r
subway_data = 
  read_csv("HW2_Data/NYC_Transit_Subway_Entrance_And_Exit_Data.csv") %>%

  janitor::clean_names() %>%
  
  select(line, station_name, station_latitude, station_longitude, route1:route11, entry, exit_only, vending, entrance_type, ada) %>%
  
  mutate(entry = recode(entry, "YES" = 1, "NO" = 0))

head(subway_data, 20)
```

    ## # A tibble: 20 × 20
    ##    line     station_…¹ stati…² stati…³ route1 route2 route3 route4 route5 route6
    ##    <chr>    <chr>        <dbl>   <dbl> <chr>  <chr>  <chr>  <chr>  <chr>  <chr> 
    ##  1 4 Avenue 25th St       40.7   -74.0 R      <NA>   <NA>   <NA>   <NA>   <NA>  
    ##  2 4 Avenue 25th St       40.7   -74.0 R      <NA>   <NA>   <NA>   <NA>   <NA>  
    ##  3 4 Avenue 36th St       40.7   -74.0 N      R      <NA>   <NA>   <NA>   <NA>  
    ##  4 4 Avenue 36th St       40.7   -74.0 N      R      <NA>   <NA>   <NA>   <NA>  
    ##  5 4 Avenue 36th St       40.7   -74.0 N      R      <NA>   <NA>   <NA>   <NA>  
    ##  6 4 Avenue 45th St       40.6   -74.0 R      <NA>   <NA>   <NA>   <NA>   <NA>  
    ##  7 4 Avenue 45th St       40.6   -74.0 R      <NA>   <NA>   <NA>   <NA>   <NA>  
    ##  8 4 Avenue 45th St       40.6   -74.0 R      <NA>   <NA>   <NA>   <NA>   <NA>  
    ##  9 4 Avenue 45th St       40.6   -74.0 R      <NA>   <NA>   <NA>   <NA>   <NA>  
    ## 10 4 Avenue 53rd St       40.6   -74.0 R      <NA>   <NA>   <NA>   <NA>   <NA>  
    ## 11 4 Avenue 53rd St       40.6   -74.0 R      <NA>   <NA>   <NA>   <NA>   <NA>  
    ## 12 4 Avenue 53rd St       40.6   -74.0 R      <NA>   <NA>   <NA>   <NA>   <NA>  
    ## 13 4 Avenue 53rd St       40.6   -74.0 R      <NA>   <NA>   <NA>   <NA>   <NA>  
    ## 14 4 Avenue 53rd St       40.6   -74.0 R      <NA>   <NA>   <NA>   <NA>   <NA>  
    ## 15 4 Avenue 59th St       40.6   -74.0 N      R      <NA>   <NA>   <NA>   <NA>  
    ## 16 4 Avenue 59th St       40.6   -74.0 N      R      <NA>   <NA>   <NA>   <NA>  
    ## 17 4 Avenue 59th St       40.6   -74.0 N      R      <NA>   <NA>   <NA>   <NA>  
    ## 18 4 Avenue 59th St       40.6   -74.0 N      R      <NA>   <NA>   <NA>   <NA>  
    ## 19 4 Avenue 59th St       40.6   -74.0 N      R      <NA>   <NA>   <NA>   <NA>  
    ## 20 4 Avenue 59th St       40.6   -74.0 N      R      <NA>   <NA>   <NA>   <NA>  
    ## # … with 10 more variables: route7 <chr>, route8 <dbl>, route9 <dbl>,
    ## #   route10 <dbl>, route11 <dbl>, entry <dbl>, exit_only <chr>, vending <chr>,
    ## #   entrance_type <chr>, ada <lgl>, and abbreviated variable names
    ## #   ¹​station_name, ²​station_latitude, ³​station_longitude

This data contains information about the different subway lines in New
York City, the locations of their stations and the different routes they
operate on. This data set also has information on whether the entrance
types for the stations, whether the stations contain vendors and whether
they are compliant with the Americans with Disabilities Act.

-   The number of rows in this data set are 1868 and the number of
    columns are 20

-   The number of distinct stations are 465

``` r
names_and_ada = distinct(subway_data, line, station_name, ada)

ADA_compliant = sum(names_and_ada$ada, na.rm = TRUE)
```

-   The number of ADA compliant stations is 84

-   The proportion of stations without vending that allow entrance is
    given below

``` r
subway_data %>%
  filter(vending != "YES") %>%
  pull(entry) %>%
mean
```

    ## [1] 0.3770492

-   This shows that 37.7% of subway stations without vending also allow
    entrance.

Now we find the number of stations serving the A train and which of
these are ADA compliant.

``` r
route_number_and_name = distinct(subway_data, station_name, line, ada, across(contains("route")))

A_stations = filter(route_number_and_name, route1 == "A")

A_stations_with_ADA = filter(A_stations, ada == "TRUE")
```

-   The number of stations that serve the A train are 60

-   The number of stations that serve the A train and are ADA compliant
    are 17

## Problem 2

Now we will read in an excel file for Mr. Trash Wheel

``` r
mr_trash_wheel = 
  read_excel("HW2_Data/Trash Wheel Collection Data.xlsx", sheet = "Mr. Trash Wheel", skip = 1, na = "", range = cell_cols(1:14)) %>%
  
  janitor::clean_names() %>%
  
  na.omit() %>%
  
  mutate(sports_balls = as.integer(round(sports_balls))) %>%
  
  select(-date)


head(mr_trash_wheel, 20)
```

    ## # A tibble: 20 × 13
    ##    dumpster month year  weight…¹ volum…² plast…³ polys…⁴ cigar…⁵ glass…⁶ groce…⁷
    ##       <dbl> <chr> <chr>    <dbl>   <dbl>   <dbl>   <dbl>   <dbl>   <dbl>   <dbl>
    ##  1        1 May   2014      4.31      18    1450    1820  126000      72     584
    ##  2        2 May   2014      2.74      13    1120    1030   91000      42     496
    ##  3        3 May   2014      3.45      15    2450    3100  105000      50    1080
    ##  4        4 May   2014      3.1       15    2380    2730  100000      52     896
    ##  5        5 May   2014      4.06      18     980     870  120000      72     368
    ##  6        6 May   2014      2.71      13    1430    2140   90000      46     672
    ##  7        7 May   2014      1.91       8     910    1090   56000      32     416
    ##  8        8 May   2014      3.7       16    3580    4310  112000      58    1552
    ##  9        9 June  2014      2.52      14    2400    2790   98000      49     984
    ## 10       10 June  2014      3.76      18    1340    1730  130000      75     448
    ## 11       11 June  2014      3.43      15     740     869  110000      38     344
    ## 12       12 June  2014      4.17      19     950    1140  133000      45     520
    ## 13       13 June  2014      5.13      15     530     630  104000      58     224
    ## 14       14 June  2014      4.17      15     840     760  100000      62     344
    ## 15       15 June  2014      3.28      15    1130    1350  102000      64     432
    ## 16       16 June  2014      3.05      15    1640    2130  106000      56     752
    ## 17       17 June  2014      2.49      13    1350    1620   89000      47     696
    ## 18       18 July  2014      2.54      15    1640    1960  108000      65     744
    ## 19       19 July  2014      2.41      15    1730    2100  107000      63     896
    ## 20       20 July  2014      3.83      18    5960    6540  132000      79    2560
    ## # … with 3 more variables: chip_bags <dbl>, sports_balls <int>,
    ## #   homes_powered <dbl>, and abbreviated variable names ¹​weight_tons,
    ## #   ²​volume_cubic_yards, ³​plastic_bottles, ⁴​polystyrene, ⁵​cigarette_butts,
    ## #   ⁶​glass_bottles, ⁷​grocery_bags

Now we import the professor trash wheel data set

``` r
prof_trash_wheel = 
  read_excel("HW2_Data/Trash Wheel Collection Data.xlsx", sheet = "Professor Trash Wheel", skip = 1, na = "") %>%
  
  janitor::clean_names() %>%
  
  na.omit() %>%
  
  select(-date)


head(prof_trash_wheel, 20)
```

    ## # A tibble: 20 × 12
    ##    dumpster month   year weigh…¹ volum…² plast…³ polys…⁴ cigar…⁵ glass…⁶ groce…⁷
    ##       <dbl> <chr>  <dbl>   <dbl>   <dbl>   <dbl>   <dbl>   <dbl>   <dbl>   <dbl>
    ##  1        1 Janua…  2017    1.79      15    1950    6080   19700       8    3100
    ##  2        2 Janua…  2017    1.58      15    9540   11230   17600      14    5630
    ##  3        3 Febru…  2017    2.32      18    8350    9210   12000      19    6430
    ##  4        4 Febru…  2017    3.72      15    8590    1030   13000      21    5870
    ##  5        5 Febru…  2017    1.45      15    7830    9950   16000      18    7450
    ##  6        6 March   2017    1.71      15    8210   10340   14000      23    9560
    ##  7        7 April   2017    1.82      15    9830   11020   17000      26   11500
    ##  8        8 April   2017    2.37      15    9240    8760   15000      14    9970
    ##  9        9 May     2017    2.64      15    9540    8810   17000      28   12340
    ## 10       10 May     2017    2.78      15    8230    7800   13000      22   13450
    ## 11       11 June    2017    2.34      15    7540    8260   14000      12   10320
    ## 12       12 July    2017    1.63      15    8490    8230   16000      24    8870
    ## 13       13 July    2017    2.37      15    9610    9480   19000      27   13400
    ## 14       14 July    2017    1.69      15    7960    7650   12000      17    9540
    ## 15       15 August  2017    2.93      15    8870    8530   21000      32   11600
    ## 16       16 August  2017    1.21      15    7420    7280   15000      18    9710
    ## 17       17 Septe…  2017    1.47      15    8250    7860   14000      24    8940
    ## 18       18 Novem…  2017    0.75       8    8472   11528   33320       0     656
    ## 19       19 Janua…  2018    0.99      15    7530    9240   22400       6     940
    ## 20       20 Febru…  2018    1.58      15    2340    3780   24000       4    1870
    ## # … with 2 more variables: chip_bags <dbl>, homes_powered <dbl>, and
    ## #   abbreviated variable names ¹​weight_tons, ²​volume_cubic_yards,
    ## #   ³​plastic_bottles, ⁴​polystyrene, ⁵​cigarette_butts, ⁶​glass_bottles,
    ## #   ⁷​grocery_bags

Now we combine Mr. Trash Wheel and Professor Trash Wheel datasets

``` r
mr_trash_wheel$dumpster = as.double(mr_trash_wheel$dumpster)

mr_trash_wheel$year = as.double(mr_trash_wheel$year)

trash_wheel_combined = 
  bind_rows(mr_trash_wheel, prof_trash_wheel, .id = "trash_wheel_type")
  

head(trash_wheel_combined, 20)
```

    ## # A tibble: 20 × 14
    ##    trash_w…¹ dumps…² month  year weigh…³ volum…⁴ plast…⁵ polys…⁶ cigar…⁷ glass…⁸
    ##    <chr>       <dbl> <chr> <dbl>   <dbl>   <dbl>   <dbl>   <dbl>   <dbl>   <dbl>
    ##  1 1               1 May    2014    4.31      18    1450    1820  126000      72
    ##  2 1               2 May    2014    2.74      13    1120    1030   91000      42
    ##  3 1               3 May    2014    3.45      15    2450    3100  105000      50
    ##  4 1               4 May    2014    3.1       15    2380    2730  100000      52
    ##  5 1               5 May    2014    4.06      18     980     870  120000      72
    ##  6 1               6 May    2014    2.71      13    1430    2140   90000      46
    ##  7 1               7 May    2014    1.91       8     910    1090   56000      32
    ##  8 1               8 May    2014    3.7       16    3580    4310  112000      58
    ##  9 1               9 June   2014    2.52      14    2400    2790   98000      49
    ## 10 1              10 June   2014    3.76      18    1340    1730  130000      75
    ## 11 1              11 June   2014    3.43      15     740     869  110000      38
    ## 12 1              12 June   2014    4.17      19     950    1140  133000      45
    ## 13 1              13 June   2014    5.13      15     530     630  104000      58
    ## 14 1              14 June   2014    4.17      15     840     760  100000      62
    ## 15 1              15 June   2014    3.28      15    1130    1350  102000      64
    ## 16 1              16 June   2014    3.05      15    1640    2130  106000      56
    ## 17 1              17 June   2014    2.49      13    1350    1620   89000      47
    ## 18 1              18 July   2014    2.54      15    1640    1960  108000      65
    ## 19 1              19 July   2014    2.41      15    1730    2100  107000      63
    ## 20 1              20 July   2014    3.83      18    5960    6540  132000      79
    ## # … with 4 more variables: grocery_bags <dbl>, chip_bags <dbl>,
    ## #   sports_balls <int>, homes_powered <dbl>, and abbreviated variable names
    ## #   ¹​trash_wheel_type, ²​dumpster, ³​weight_tons, ⁴​volume_cubic_yards,
    ## #   ⁵​plastic_bottles, ⁶​polystyrene, ⁷​cigarette_butts, ⁸​glass_bottles

This combined data set contains dumpster data for two different
waterfront trash wheels in Baltimore, Maryland. They are operated by a
company called Healthy Harbor which aims to use these trash wheels to
clean and gather trash floating in the harbor in Baltimore. The director
of the program, Adam Lindquist, describes the operation as “Trash
collected by the Trash Wheel is immediately dumped into a dumpster
sitting on a separate barge at the back of the device. Each time the
dumpster fills it is removed by boat and replaced with an empty
dumpster. The full dumpster is transported to a waste-to-energy plant
with the trash is incinerated to make electricity for Maryland homes.”
The combined dumpsters data set contains 568 observations where
trash_wheel_type = 1 is the Mr. Trash Wheel data set and
trash_wheel_type = 2 is the Professor Trash Wheel data set. Key
variables are trash_wheel_type, dumpster, month, year, weight_tons,
volume_cubic_yards, plastic_bottles, polystyrene, cigarette_butts,
glass_bottles, grocery_bags, chip_bags, sports_balls, homes_powered.

-   The total weight of trash collected by Professor Trash Wheel from
    2017 - 2020 was 162.54 tons.

-   The total number of sports balls collected by Mr. Trash Wheel in
    2020 was 856 balls.

## Problem 3

First we read in the pols-month data

``` r
polls_monthly = 
  read_csv("HW2_Data/pols-month.csv", na = "") %>%
  
  janitor::clean_names() %>%
  
  na.omit() %>%
  
  separate(mon, into = c("month", "day", "year")) %>%
  
  mutate(year = as.integer(year), month = as.integer(month), day = as.integer(day)) %>%
  
  mutate(month = month.name[month]) %>%

  mutate(president = ifelse(prez_gop == 0, "dem", "gop")) %>%
  
  select(-prez_dem, -prez_gop, -day) %>%
  
  relocate(year, .before = month)
  

head(polls_monthly, 20)
```

    ## # A tibble: 20 × 9
    ##     year month     gov_gop sen_gop rep_gop gov_dem sen_dem rep_dem president
    ##    <int> <chr>       <dbl>   <dbl>   <dbl>   <dbl>   <dbl>   <dbl> <chr>    
    ##  1  1947 January        23      51     253      23      45     198 dem      
    ##  2  1947 February       23      51     253      23      45     198 dem      
    ##  3  1947 March          23      51     253      23      45     198 dem      
    ##  4  1947 April          23      51     253      23      45     198 dem      
    ##  5  1947 May            23      51     253      23      45     198 dem      
    ##  6  1947 June           23      51     253      23      45     198 dem      
    ##  7  1947 July           23      51     253      23      45     198 dem      
    ##  8  1947 August         23      51     253      23      45     198 dem      
    ##  9  1947 September      23      51     253      23      45     198 dem      
    ## 10  1947 October        23      51     253      23      45     198 dem      
    ## 11  1947 November       24      51     253      23      45     198 dem      
    ## 12  1947 December       24      51     253      23      45     198 dem      
    ## 13  1948 January        22      53     253      24      48     198 dem      
    ## 14  1948 February       22      53     253      24      48     198 dem      
    ## 15  1948 March          22      53     253      24      48     198 dem      
    ## 16  1948 April          22      53     253      24      48     198 dem      
    ## 17  1948 May            22      53     253      24      48     198 dem      
    ## 18  1948 June           22      53     253      24      48     198 dem      
    ## 19  1948 July           22      53     253      24      48     198 dem      
    ## 20  1948 August         22      53     253      24      48     198 dem

Next we read in the s&p stock data

``` r
snp_stock_data = 
  read_csv("HW2_Data/snp.csv", na = "") %>%
  
  janitor::clean_names() %>%
  
  na.omit() %>%
  
  separate(date, into = c("month", "day", "year")) %>%
  
  mutate(year = as.integer(year), month = as.integer(month), day = as.integer(day)) %>%
  
  mutate(year_change = ifelse(year < 22, 2000, 1900)) %>%
  
  mutate(year = as.integer(year_change + year)) %>%
  
  mutate(month = month.name[month]) %>%

  select(-day, -year_change) %>%
  
  relocate(year, .before = month)


head(snp_stock_data, 20)
```

    ## # A tibble: 20 × 3
    ##     year month     close
    ##    <int> <chr>     <dbl>
    ##  1  2015 July      2080.
    ##  2  2015 June      2063.
    ##  3  2015 May       2107.
    ##  4  2015 April     2086.
    ##  5  2015 March     2068.
    ##  6  2015 February  2104.
    ##  7  2015 January   1995.
    ##  8  2014 December  2059.
    ##  9  2014 November  2068.
    ## 10  2014 October   2018.
    ## 11  2014 September 1972.
    ## 12  2014 August    2003.
    ## 13  2014 July      1931.
    ## 14  2014 June      1960.
    ## 15  2014 May       1924.
    ## 16  2014 April     1884.
    ## 17  2014 March     1872.
    ## 18  2014 February  1859.
    ## 19  2014 January   1783.
    ## 20  2013 December  1848.

Now we will import the unemployment data

``` r
unemployment = 
  read_csv("HW2_Data/unemployment.csv", na = "") %>%
  
  janitor::clean_names() %>%
  
  na.omit() %>%
  
  pivot_longer(
    jan:dec, names_to = "month", values_to = "unemployment %") %>%
  
  mutate(
      month = replace(month, month == "jan", 1),
      month = replace(month, month == "feb", 2),
      month = replace(month, month == "mar", 3),
      month = replace(month, month == "apr", 4), 
      month = replace(month, month == "may", 5),
      month = replace(month, month == "jun", 6),
      month = replace(month, month == "jul", 7),
      month = replace(month, month == "aug", 8),
      month = replace(month, month == "sep", 9),
      month = replace(month, month == "oct", 10),
      month = replace(month, month == "nov", 11),
      month = replace(month, month == "dec", 12)
  ) %>%
  
  mutate(
    year = as.integer(year), month = as.integer(month)
    ) %>%
  
  mutate(month = month.name[month])


head(unemployment, 20)
```

    ## # A tibble: 20 × 3
    ##     year month     `unemployment %`
    ##    <int> <chr>                <dbl>
    ##  1  1948 January                3.4
    ##  2  1948 February               3.8
    ##  3  1948 March                  4  
    ##  4  1948 April                  3.9
    ##  5  1948 May                    3.5
    ##  6  1948 June                   3.6
    ##  7  1948 July                   3.6
    ##  8  1948 August                 3.9
    ##  9  1948 September              3.8
    ## 10  1948 October                3.7
    ## 11  1948 November               3.8
    ## 12  1948 December               4  
    ## 13  1949 January                4.3
    ## 14  1949 February               4.7
    ## 15  1949 March                  5  
    ## 16  1949 April                  5.3
    ## 17  1949 May                    6.1
    ## 18  1949 June                   6.2
    ## 19  1949 July                   6.7
    ## 20  1949 August                 6.8

Now we will join all three data sets by first combining s&p into pols
then combining with unemployment data.

``` r
snp_into_pols = 
  left_join(polls_monthly, snp_stock_data, by = c("year", "month"))

head(snp_into_pols, 20)
```

    ## # A tibble: 20 × 10
    ##     year month     gov_gop sen_gop rep_gop gov_dem sen_dem rep_dem presi…¹ close
    ##    <int> <chr>       <dbl>   <dbl>   <dbl>   <dbl>   <dbl>   <dbl> <chr>   <dbl>
    ##  1  1947 January        23      51     253      23      45     198 dem        NA
    ##  2  1947 February       23      51     253      23      45     198 dem        NA
    ##  3  1947 March          23      51     253      23      45     198 dem        NA
    ##  4  1947 April          23      51     253      23      45     198 dem        NA
    ##  5  1947 May            23      51     253      23      45     198 dem        NA
    ##  6  1947 June           23      51     253      23      45     198 dem        NA
    ##  7  1947 July           23      51     253      23      45     198 dem        NA
    ##  8  1947 August         23      51     253      23      45     198 dem        NA
    ##  9  1947 September      23      51     253      23      45     198 dem        NA
    ## 10  1947 October        23      51     253      23      45     198 dem        NA
    ## 11  1947 November       24      51     253      23      45     198 dem        NA
    ## 12  1947 December       24      51     253      23      45     198 dem        NA
    ## 13  1948 January        22      53     253      24      48     198 dem        NA
    ## 14  1948 February       22      53     253      24      48     198 dem        NA
    ## 15  1948 March          22      53     253      24      48     198 dem        NA
    ## 16  1948 April          22      53     253      24      48     198 dem        NA
    ## 17  1948 May            22      53     253      24      48     198 dem        NA
    ## 18  1948 June           22      53     253      24      48     198 dem        NA
    ## 19  1948 July           22      53     253      24      48     198 dem        NA
    ## 20  1948 August         22      53     253      24      48     198 dem        NA
    ## # … with abbreviated variable name ¹​president

``` r
unemployment_snp_pols = 
  left_join(snp_into_pols, unemployment, by = c("year", "month"))

head(unemployment_snp_pols, 20)
```

    ## # A tibble: 20 × 11
    ##     year month     gov_gop sen_gop rep_gop gov_dem sen_dem rep_dem presi…¹ close
    ##    <int> <chr>       <dbl>   <dbl>   <dbl>   <dbl>   <dbl>   <dbl> <chr>   <dbl>
    ##  1  1947 January        23      51     253      23      45     198 dem        NA
    ##  2  1947 February       23      51     253      23      45     198 dem        NA
    ##  3  1947 March          23      51     253      23      45     198 dem        NA
    ##  4  1947 April          23      51     253      23      45     198 dem        NA
    ##  5  1947 May            23      51     253      23      45     198 dem        NA
    ##  6  1947 June           23      51     253      23      45     198 dem        NA
    ##  7  1947 July           23      51     253      23      45     198 dem        NA
    ##  8  1947 August         23      51     253      23      45     198 dem        NA
    ##  9  1947 September      23      51     253      23      45     198 dem        NA
    ## 10  1947 October        23      51     253      23      45     198 dem        NA
    ## 11  1947 November       24      51     253      23      45     198 dem        NA
    ## 12  1947 December       24      51     253      23      45     198 dem        NA
    ## 13  1948 January        22      53     253      24      48     198 dem        NA
    ## 14  1948 February       22      53     253      24      48     198 dem        NA
    ## 15  1948 March          22      53     253      24      48     198 dem        NA
    ## 16  1948 April          22      53     253      24      48     198 dem        NA
    ## 17  1948 May            22      53     253      24      48     198 dem        NA
    ## 18  1948 June           22      53     253      24      48     198 dem        NA
    ## 19  1948 July           22      53     253      24      48     198 dem        NA
    ## 20  1948 August         22      53     253      24      48     198 dem        NA
    ## # … with 1 more variable: `unemployment %` <dbl>, and abbreviated variable name
    ## #   ¹​president

``` r
view(unemployment_snp_pols)
```

Each data set includes historical data for national politicians and
their affiliated political party, s&p stock prices, and unemployment
rates over time. Combining this data together is intended to display
correlation between political party changes, unemployment rates, and
stock market behavior over time.

The variables in the polls data set is year, month, gov_gop, sen_gop,
rep_gop, gov_dem, sen_dem, rep_dem, president, variables in the s&p data
set are year, month, close, variables in the unemployment data set are
year, month, unemployment %, and the variables in the combined data set
are year, month, gov_gop, sen_gop, rep_gop, gov_dem, sen_dem, rep_dem,
president, close, unemployment %.

The range of years of the data sets are 1947 - 2015.

The dimensions of the polling data set are 822, 9, the dimensions of the
s&p data set are 787, 3, the dimensions of the unemployment data set are
804, 3, and the dimensions of the combined data set are 822, 11.
